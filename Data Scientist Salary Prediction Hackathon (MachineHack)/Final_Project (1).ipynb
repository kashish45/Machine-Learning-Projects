{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T82aEDuHwhG2"
   },
   "outputs": [],
   "source": [
    "#Problem Statement.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzcgvSMwwhHC"
   },
   "source": [
    "Data scientist is the sexiest job in the world. How many times have you heard that? Analytics India Annual Salary Study which aims to understand a wide range of trends data science says that the median analytics salary in India for the year 2017 is INR 12.7 Lakhs across all experience level and skill sets. So given the job description and other key information can you predict the range of salary of the job posting? What kind of factors influence the salary of a data scientist? The study also says that in the world of analytics, Mumbai is the highest paymaster at almost 13.3 Lakhs per annum, followed by Bengaluru at 12.5 Lakhs. The industry of the data scientist can also influence the salary. Telecom industry pays the highest median salaries to its analytics professionals at 18.6 Lakhs. What are you waiting for, solve the problem by predicting how much a data scientist or analytics professional will be paid by analysing the data given. Bonus Tip: You can analyse the data and get key insights for your career as well. The best data scientists and machine learning engineers will be given awesome prizes at the end of hackathon. Share this hackathon with a colleague who may be interested in mining the dataset for insights and make great predictions. Data The dataset is based on salary and job postings in India across the internet. The train and the test data consists of attributes mentioned below. The rows of train dataset has rich amount of information regarding the job posting such as name of the designation and key skills required for the job. The training data and test data comprise of 19802 samples and of 6601 samples each. This is a dataset which has been collected over some time to gather relevant analytics jobs posting over the years. Features Name of the company (Encoded) Years of experience Job description Job designation Job Type Key skills Location Salary in Rupees Lakhs(To be predicted) Problem Statement Based on the given attributes and salary information, build a robust machine learning model that predicts the salary range of the salary post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hs_Hf1JwhHE"
   },
   "source": [
    "# Acheived Rank 8 in this Machine Learning Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N9QQSqgAwhHF"
   },
   "outputs": [],
   "source": [
    "#IMPORTING The Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nxe_nnRBwhHF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlnK0e-nwhHG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "P4sl6R80whHG"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('Final_Train_Dataset.csv',usecols=['experience', 'job_description', 'job_desig', 'job_type',\n",
    "       'key_skills', 'location', 'salary', 'company_name_encoded'])\n",
    "test_data=pd.read_csv('Final_Test_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "A3VEHub-whHH",
    "outputId": "c6642c98-c0ce-4da0-a0f7-e9c62cde5162"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_type</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>company_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-7 yrs</td>\n",
       "      <td>Exp: Minimum 5 years;Good understanding of IOC...</td>\n",
       "      <td>Senior Exploit and Vulnerability Researcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>team skills, communication skills, analytical ...</td>\n",
       "      <td>Delhi NCR(Vikas Puri)</td>\n",
       "      <td>6to10</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-17 yrs</td>\n",
       "      <td>He should have handled a team of atleast 5-6 d...</td>\n",
       "      <td>Head SCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ppc, logistics, inventory management, supply c...</td>\n",
       "      <td>Sonepat</td>\n",
       "      <td>10to15</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience                                    job_description  \\\n",
       "0    5-7 yrs  Exp: Minimum 5 years;Good understanding of IOC...   \n",
       "1  10-17 yrs  He should have handled a team of atleast 5-6 d...   \n",
       "\n",
       "                                     job_desig job_type  \\\n",
       "0  Senior Exploit and Vulnerability Researcher      NaN   \n",
       "1                                     Head SCM      NaN   \n",
       "\n",
       "                                          key_skills               location  \\\n",
       "0  team skills, communication skills, analytical ...  Delhi NCR(Vikas Puri)   \n",
       "1  ppc, logistics, inventory management, supply c...                Sonepat   \n",
       "\n",
       "   salary  company_name_encoded  \n",
       "0   6to10                  3687  \n",
       "1  10to15                   458  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4vXhlsqJwhHJ",
    "outputId": "de736ab4-9a12-4e9b-edf6-ad99a7174eb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_type</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>location</th>\n",
       "      <th>company_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7-12 yrs</td>\n",
       "      <td>Professional experience in Java/J2EE based ser...</td>\n",
       "      <td>IT Technology Senior Consultant/java/ J2ee/ Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Java, J2Ee, Tomcat, JBoss, Weblogic, Oracle, E...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-5 yrs</td>\n",
       "      <td>We are looking for 20+ Fresher/Experienced Can...</td>\n",
       "      <td>Medical Billing Process | International KPO | ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medical Billing, Insurance Processing</td>\n",
       "      <td>Ahmedabad(Sola)</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience                                    job_description  \\\n",
       "0   7-12 yrs  Professional experience in Java/J2EE based ser...   \n",
       "1    0-5 yrs  We are looking for 20+ Fresher/Experienced Can...   \n",
       "\n",
       "                                           job_desig job_type  \\\n",
       "0  IT Technology Senior Consultant/java/ J2ee/ Se...      NaN   \n",
       "1  Medical Billing Process | International KPO | ...      NaN   \n",
       "\n",
       "                                          key_skills         location  \\\n",
       "0  Java, J2Ee, Tomcat, JBoss, Weblogic, Oracle, E...        Bengaluru   \n",
       "1              Medical Billing, Insurance Processing  Ahmedabad(Sola)   \n",
       "\n",
       "   company_name_encoded  \n",
       "0                  2066  \n",
       "1                  2629  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XYbA3aRwhHK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ho9U0M-kwhHK"
   },
   "outputs": [],
   "source": [
    "train_data['job_type'].fillna('missingjobtype', inplace=True)\n",
    "train_data['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "train_data['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "train_data['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "train_data['job_type'].replace('analytic', 'analytics', inplace=True)\n",
    "\n",
    "test_data['job_type'].fillna('missingjobtype', inplace=True)\n",
    "test_data['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "test_data['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "test_data['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "test_data['job_type'].replace('analytic', 'analytics', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Oe48DydHwhHL"
   },
   "outputs": [],
   "source": [
    "train_data.dropna(subset=['key_skills'],inplace=True)\n",
    "test_data.dropna(subset=['key_skills'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "E69P-06wwhHL"
   },
   "outputs": [],
   "source": [
    "#For Descriptions which have Nan Values , we would replace them with the \"Missing Description\"\n",
    "train_data['job_description'].fillna(\"Missing Description\",inplace=True)\n",
    "#For Descriptions which have Nan Values , we would replace them with the \"Missing Description\"\n",
    "test_data['job_description'].fillna(\"Missing Description\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cBI32gRcwhHM",
    "outputId": "50ea0483-a733-4080-952f-212a868edcb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19801 entries, 0 to 19801\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   experience            19801 non-null  object\n",
      " 1   job_description       19801 non-null  object\n",
      " 2   job_desig             19801 non-null  object\n",
      " 3   job_type              19801 non-null  object\n",
      " 4   key_skills            19801 non-null  object\n",
      " 5   location              19801 non-null  object\n",
      " 6   salary                19801 non-null  object\n",
      " 7   company_name_encoded  19801 non-null  int64 \n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "hj5D9c5awhHM",
    "outputId": "a26c58a5-69e9-44e7-a70b-876d5c837f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6601 entries, 0 to 6600\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   experience            6601 non-null   object\n",
      " 1   job_description       6601 non-null   object\n",
      " 2   job_desig             6601 non-null   object\n",
      " 3   job_type              6601 non-null   object\n",
      " 4   key_skills            6601 non-null   object\n",
      " 5   location              6601 non-null   object\n",
      " 6   company_name_encoded  6601 non-null   int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 412.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "twdBNp_MwhHN"
   },
   "outputs": [],
   "source": [
    "train_data['Minimum_experience']=train_data['experience'].apply(lambda x:x.split('-')[0])\n",
    "train_data['Maximum_experience']=train_data['experience'].apply(lambda x:x.split('-')[1])\n",
    "train_data['Maximum_experience']=train_data['Maximum_experience'].apply(lambda x:x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Z5bXvHKuwhHN"
   },
   "outputs": [],
   "source": [
    "test_data['Minimum_experience']=test_data['experience'].apply(lambda x:x.split('-')[0])\n",
    "test_data['Maximum_experience']=test_data['experience'].apply(lambda x:x.split('-')[1])\n",
    "test_data['Maximum_experience']=test_data['Maximum_experience'].apply(lambda x:x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zoG0emawhHN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "BL26h0lzwhHO"
   },
   "outputs": [],
   "source": [
    "#cleaning unecessary tokens in skills for better understanding for algorithms...\n",
    "def clean_skills(skill):\n",
    "    skills=str(skill).lower()\n",
    "    skills=re.sub(r'\\...',' ',skills)\n",
    "    skills=re.sub(r',',' ',skills)\n",
    "    skills=re.sub('\\s+',' ',skills)\n",
    "    return skills\n",
    "\n",
    "train_data['Key_Skills']=train_data['key_skills'].apply(clean_skills)\n",
    "test_data['Key_Skills']=test_data['key_skills'].apply(clean_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "BmafTjMAwhHP",
    "outputId": "896da00c-921c-4349-97ba-4a0c95973828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('team skills communication skills analytical skills problem solving ',\n",
       " 'ppc logistics inventory management supply chain management procurement ')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Key_Skills'][0],train_data['Key_Skills'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Mg4f6QHwhHQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "FNzx3jOnwhHR"
   },
   "outputs": [],
   "source": [
    "#Since there are a lot of unnecessary tokens in the text, we  have to clean those for further better understanding , so that \n",
    "#algorithms learn our data better...\n",
    "def clean_description(description):\n",
    "    desc=str(description).lower()\n",
    "    desc=re.sub(r',',' ',desc)\n",
    "    desc=re.sub(r'/...',' ',desc)\n",
    "    desc=re.sub(r'[^a-z]',' ',desc)\n",
    "    desc=re.sub('\\s+',' ',desc)\n",
    "    return desc\n",
    "\n",
    "\n",
    "train_data['JOB_DESCRIPTION']=train_data['job_description'].apply(clean_description)\n",
    "test_data['JOB_DESCRIPTION']=test_data['job_description'].apply(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "dN-RgDxRwhHS"
   },
   "outputs": [],
   "source": [
    "def clean_desig(desig):\n",
    "    designation=str(desig).lower()\n",
    "    designation=re.sub('[^a-z]',' ',designation)\n",
    "    designation=re.sub('\\s+',' ',designation)\n",
    "    return designation\n",
    "\n",
    "train_data['Job_Desig']=train_data['job_desig'].apply(clean_desig)\n",
    "test_data['Job_Desig']=test_data['job_desig'].apply(clean_desig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "A8f2JrfPwhHT"
   },
   "outputs": [],
   "source": [
    "def clean_location(loc):\n",
    "    location = loc.lower()\n",
    "    location = re.sub(r'[^a-z]', ' ', location)\n",
    "    location = re.sub(r'\\s+', ' ', location)\n",
    "    return location\n",
    "\n",
    "train_data['Location'] = train_data['location'].apply(clean_location)\n",
    "test_data['Location'] = test_data['location'].apply(clean_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0l7A6pNwhHU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ynx0DL1zwhHU"
   },
   "outputs": [],
   "source": [
    "train_data.drop(['job_description','job_desig','location','key_skills'],1,inplace=True)\n",
    "test_data.drop(['job_description','job_desig','location','key_skills'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "gPkR-k4gwhHU"
   },
   "outputs": [],
   "source": [
    "train_data.drop(['experience'],1,inplace=True)\n",
    "test_data.drop(['experience'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "itpnmfo5whHV",
    "outputId": "b9fd0ca5-6d1e-45bf-d3c7-4066cafd54d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_type</th>\n",
       "      <th>salary</th>\n",
       "      <th>company_name_encoded</th>\n",
       "      <th>Minimum_experience</th>\n",
       "      <th>Maximum_experience</th>\n",
       "      <th>Key_Skills</th>\n",
       "      <th>JOB_DESCRIPTION</th>\n",
       "      <th>Job_Desig</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missingjobtype</td>\n",
       "      <td>6to10</td>\n",
       "      <td>3687</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>team skills communication skills analytical sk...</td>\n",
       "      <td>exp minimum years good understanding of ioc ru...</td>\n",
       "      <td>senior exploit and vulnerability researcher</td>\n",
       "      <td>delhi ncr vikas puri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missingjobtype</td>\n",
       "      <td>10to15</td>\n",
       "      <td>458</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>ppc logistics inventory management supply chai...</td>\n",
       "      <td>he should have handled a team of atleast direc...</td>\n",
       "      <td>head scm</td>\n",
       "      <td>sonepat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job_type  salary  company_name_encoded Minimum_experience  \\\n",
       "0  missingjobtype   6to10                  3687                  5   \n",
       "1  missingjobtype  10to15                   458                 10   \n",
       "\n",
       "  Maximum_experience                                         Key_Skills  \\\n",
       "0                  7  team skills communication skills analytical sk...   \n",
       "1                 17  ppc logistics inventory management supply chai...   \n",
       "\n",
       "                                     JOB_DESCRIPTION  \\\n",
       "0  exp minimum years good understanding of ioc ru...   \n",
       "1  he should have handled a team of atleast direc...   \n",
       "\n",
       "                                     Job_Desig               Location  \n",
       "0  senior exploit and vulnerability researcher  delhi ncr vikas puri   \n",
       "1                                     head scm                sonepat  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "487-dAqywhHV"
   },
   "outputs": [],
   "source": [
    "#Do Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "sXWBEMhvwhHV"
   },
   "outputs": [],
   "source": [
    "train_data['merged_text']=(train_data['Job_Desig'] + ' ' + train_data['JOB_DESCRIPTION'] + ' ' + train_data['Key_Skills']\n",
    "                      + ' ' + train_data['job_type'])\n",
    "\n",
    "test_data['merged_text']=(test_data['Job_Desig'] + ' ' + test_data['JOB_DESCRIPTION'] + ' ' + test_data['Key_Skills']\n",
    "                      + ' ' + test_data['job_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "9aJNkzljwhHW"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_data['salary'] = le.fit_transform(train_data['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "SS0SBJQYwhHW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data[['merged_text', 'Location','Minimum_experience','Maximum_experience','company_name_encoded']], \n",
    "    train_data['salary'], test_size=0.20, \n",
    "    stratify=train_data['salary'], random_state=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "wcAbwLDEwhHW"
   },
   "outputs": [],
   "source": [
    "X_train_merged = X_train['merged_text']\n",
    "X_train_location = X_train['Location']\n",
    "\n",
    "X_test_merged = X_test['merged_text']\n",
    "X_test_location = X_test['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "PlrgFlA2whHX"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "QVwdkfhhwhHY"
   },
   "outputs": [],
   "source": [
    "tf1 = TfidfVectorizer(min_df=3, token_pattern=r'\\w{3,}', ngram_range=(1,3), max_df=0.9,stop_words='english')\n",
    "tf2 = TfidfVectorizer(min_df=2, token_pattern=r'\\w{3,}',stop_words='english')\n",
    "\n",
    "X_train_merged = tf1.fit_transform(X_train_merged)\n",
    "X_train_location = tf2.fit_transform(X_train_location)\n",
    "\n",
    "X_test_merged = tf1.transform(X_test_merged)\n",
    "X_test_location = tf2.transform(X_test_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Y88E3W9mwhHZ"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "X_train_MinExp = sc1.fit_transform(np.array(X_train['Minimum_experience']).reshape(-1,1))\n",
    "X_test_MinExp = sc1.transform(np.array(X_test['Minimum_experience']).reshape(-1,1))\n",
    "X_train_MinExp = sparse.csr_matrix(X_train_MinExp)\n",
    "X_test_MinExp = sparse.csr_matrix(X_test_MinExp)\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "X_train_MaxExp = sc2.fit_transform(np.array(X_train['Maximum_experience']).reshape(-1,1))\n",
    "X_test_MaxExp = sc2.transform(np.array(X_test['Maximum_experience']).reshape(-1,1))\n",
    "X_train_MaxExp = sparse.csr_matrix(X_train_MaxExp)\n",
    "X_test_MaxExp = sparse.csr_matrix(X_test_MaxExp)\n",
    "\n",
    "sc3 = StandardScaler()\n",
    "X_train_comp = sc3.fit_transform(np.array(X_train['company_name_encoded']).reshape(-1,1))\n",
    "X_test_comp = sc3.transform(np.array(X_test['company_name_encoded']).reshape(-1,1))\n",
    "# X_train_comp=np.array(X_train['company_name_encoded']).reshape(-1,1)\n",
    "# X_test_comp=np.array(X_test['company_name_encoded']).reshape(-1,1)\n",
    "\n",
    "X_train_comp = sparse.csr_matrix(X_train_comp)\n",
    "X_test_comp = sparse.csr_matrix(X_test_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "mnLYGVliwhHZ"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "merged_train = hstack((X_train_merged, X_train_location, X_train_MinExp, X_train_MaxExp,X_train_comp))\n",
    "merged_test  = hstack((X_test_merged, X_test_location, X_test_MinExp, X_test_MaxExp,X_test_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "dDwcYuFBwhHa",
    "outputId": "086e0adb-e34c-400f-d9ab-6d2ac245448d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15840, 46913), (3961, 46913))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train.shape, merged_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "i-8Rr62HwhHb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "FVckaYJEwhHb"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train = lgb.Dataset(merged_train, label=y_train)\n",
    "test = lgb.Dataset(merged_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "DzTUGJSzwhHc"
   },
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "RA6SJ0oOwhHd"
   },
   "outputs": [],
   "source": [
    "param = {'objective': 'multiclass',\n",
    "         'num_iterations': 80,\n",
    "         'learning_rate': 0.03,  \n",
    "         'num_leaves': 15,\n",
    "         'max_depth': 15, \n",
    "         'min_data_in_leaf': 25, \n",
    "         'max_bin': 20, \n",
    "         'min_data_in_bin': 3,   \n",
    "         'num_class': 6,\n",
    "         'metric': 'multi_logloss'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "19PWhRQswhHd",
    "outputId": "93a64361-0807-4e13-867e-dac309ca32ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46391\n",
      "[LightGBM] [Info] Number of data points in the train set: 15840, number of used features: 3064\n",
      "[LightGBM] [Info] Start training from score -1.808567\n",
      "[LightGBM] [Info] Start training from score -1.481605\n",
      "[LightGBM] [Info] Start training from score -1.568616\n",
      "[LightGBM] [Info] Start training from score -2.531427\n",
      "[LightGBM] [Info] Start training from score -1.947616\n",
      "[LightGBM] [Info] Start training from score -1.724030\n",
      "[1]\tvalid_0's multi_logloss: 1.71695\n",
      "[2]\tvalid_0's multi_logloss: 1.6906\n",
      "[3]\tvalid_0's multi_logloss: 1.66625\n",
      "[4]\tvalid_0's multi_logloss: 1.64429\n",
      "[5]\tvalid_0's multi_logloss: 1.62362\n",
      "[6]\tvalid_0's multi_logloss: 1.60471\n",
      "[7]\tvalid_0's multi_logloss: 1.58709\n",
      "[8]\tvalid_0's multi_logloss: 1.57071\n",
      "[9]\tvalid_0's multi_logloss: 1.55471\n",
      "[10]\tvalid_0's multi_logloss: 1.53993\n",
      "[11]\tvalid_0's multi_logloss: 1.52605\n",
      "[12]\tvalid_0's multi_logloss: 1.51286\n",
      "[13]\tvalid_0's multi_logloss: 1.50047\n",
      "[14]\tvalid_0's multi_logloss: 1.48875\n",
      "[15]\tvalid_0's multi_logloss: 1.47752\n",
      "[16]\tvalid_0's multi_logloss: 1.46712\n",
      "[17]\tvalid_0's multi_logloss: 1.45716\n",
      "[18]\tvalid_0's multi_logloss: 1.44762\n",
      "[19]\tvalid_0's multi_logloss: 1.43885\n",
      "[20]\tvalid_0's multi_logloss: 1.42994\n",
      "[21]\tvalid_0's multi_logloss: 1.42213\n",
      "[22]\tvalid_0's multi_logloss: 1.41429\n",
      "[23]\tvalid_0's multi_logloss: 1.40681\n",
      "[24]\tvalid_0's multi_logloss: 1.39969\n",
      "[25]\tvalid_0's multi_logloss: 1.39309\n",
      "[26]\tvalid_0's multi_logloss: 1.38674\n",
      "[27]\tvalid_0's multi_logloss: 1.38058\n",
      "[28]\tvalid_0's multi_logloss: 1.37467\n",
      "[29]\tvalid_0's multi_logloss: 1.36868\n",
      "[30]\tvalid_0's multi_logloss: 1.36342\n",
      "[31]\tvalid_0's multi_logloss: 1.3581\n",
      "[32]\tvalid_0's multi_logloss: 1.35297\n",
      "[33]\tvalid_0's multi_logloss: 1.34821\n",
      "[34]\tvalid_0's multi_logloss: 1.34374\n",
      "[35]\tvalid_0's multi_logloss: 1.33932\n",
      "[36]\tvalid_0's multi_logloss: 1.33518\n",
      "[37]\tvalid_0's multi_logloss: 1.33112\n",
      "[38]\tvalid_0's multi_logloss: 1.32719\n",
      "[39]\tvalid_0's multi_logloss: 1.32326\n",
      "[40]\tvalid_0's multi_logloss: 1.31947\n",
      "[41]\tvalid_0's multi_logloss: 1.31592\n",
      "[42]\tvalid_0's multi_logloss: 1.31234\n",
      "[43]\tvalid_0's multi_logloss: 1.30885\n",
      "[44]\tvalid_0's multi_logloss: 1.3055\n",
      "[45]\tvalid_0's multi_logloss: 1.30249\n",
      "[46]\tvalid_0's multi_logloss: 1.2994\n",
      "[47]\tvalid_0's multi_logloss: 1.29661\n",
      "[48]\tvalid_0's multi_logloss: 1.29375\n",
      "[49]\tvalid_0's multi_logloss: 1.29102\n",
      "[50]\tvalid_0's multi_logloss: 1.2885\n",
      "[51]\tvalid_0's multi_logloss: 1.28612\n",
      "[52]\tvalid_0's multi_logloss: 1.28361\n",
      "[53]\tvalid_0's multi_logloss: 1.28122\n",
      "[54]\tvalid_0's multi_logloss: 1.27892\n",
      "[55]\tvalid_0's multi_logloss: 1.27654\n",
      "[56]\tvalid_0's multi_logloss: 1.2744\n",
      "[57]\tvalid_0's multi_logloss: 1.27211\n",
      "[58]\tvalid_0's multi_logloss: 1.27028\n",
      "[59]\tvalid_0's multi_logloss: 1.26818\n",
      "[60]\tvalid_0's multi_logloss: 1.26656\n",
      "[61]\tvalid_0's multi_logloss: 1.26482\n",
      "[62]\tvalid_0's multi_logloss: 1.26305\n",
      "[63]\tvalid_0's multi_logloss: 1.2613\n",
      "[64]\tvalid_0's multi_logloss: 1.25977\n",
      "[65]\tvalid_0's multi_logloss: 1.25812\n",
      "[66]\tvalid_0's multi_logloss: 1.25653\n",
      "[67]\tvalid_0's multi_logloss: 1.2549\n",
      "[68]\tvalid_0's multi_logloss: 1.25367\n",
      "[69]\tvalid_0's multi_logloss: 1.25214\n",
      "[70]\tvalid_0's multi_logloss: 1.25096\n",
      "[71]\tvalid_0's multi_logloss: 1.24969\n",
      "[72]\tvalid_0's multi_logloss: 1.24835\n",
      "[73]\tvalid_0's multi_logloss: 1.24732\n",
      "[74]\tvalid_0's multi_logloss: 1.24612\n",
      "[75]\tvalid_0's multi_logloss: 1.24501\n",
      "[76]\tvalid_0's multi_logloss: 1.24391\n",
      "[77]\tvalid_0's multi_logloss: 1.24277\n",
      "[78]\tvalid_0's multi_logloss: 1.2415\n",
      "[79]\tvalid_0's multi_logloss: 1.24037\n",
      "[80]\tvalid_0's multi_logloss: 1.23963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:597: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.train(params=param,\n",
    "                 train_set=train,\n",
    "                 num_boost_round=100,\n",
    "                 valid_sets=[test])\n",
    "\n",
    "y_pred_class = lgbm.predict(merged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "pIwHoTbOwhHd",
    "outputId": "fd69fab3-6b53-4ec7-9c86-1abdc316a6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4822014642766978\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for x in y_pred_class:\n",
    "    predictions.append(np.argmax(x))\n",
    "\n",
    "print('accuracy:', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFfMwmu18WD5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDh_tjJq8eDJ"
   },
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atv20Xfv8WMv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GakU5TY18WPG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySVFophD8WSp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Nzzx04C8lNt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ok2zlaqC8WVO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88BjXjCy8WYg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5RIi6Yo8Wat"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZnqK5B38vCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tb2ovypO8vPx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdFXwLEq8uU6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lQoebSm81-J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5qDGSxn82PU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXOpIGXt86IX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qrLTZ8S87h5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zD_FF4Z59H98"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkS76F699HBc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ObyPPRE9Lgt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "dyzoSTQ389hP",
    "outputId": "6283ac73-ad7e-4965-f03b-80c8d62b5eb0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgWZdioJ9S9f"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQRcLiEe9PTb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIoXJHShwhHe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNFDliUzwhHe"
   },
   "outputs": [],
   "source": [
    "X_train_merged = train_data['merged_text']\n",
    "X_train_location = train_data['Location']\n",
    "\n",
    "X_test_merged =test_data['merged_text']\n",
    "X_test_location =test_data['Location']\n",
    "\n",
    "y_train = train_data['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7rop--zwhHe"
   },
   "outputs": [],
   "source": [
    "tf1 = TfidfVectorizer(min_df=3, token_pattern=r'\\w{3,}', ngram_range=(1,3))\n",
    "tf2 = TfidfVectorizer(min_df=2, token_pattern=r'\\w{3,}',ngram_range=(1,2))\n",
    "\n",
    "X_train_merged = tf1.fit_transform(X_train_merged)\n",
    "X_train_location = tf2.fit_transform(X_train_location)\n",
    "\n",
    "X_test_merged = tf1.transform(X_test_merged)\n",
    "X_test_location = tf2.transform(X_test_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5pC66UywhHf"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "X_train_MinExp = sc1.fit_transform(np.array(train_data['Minimum_experience']).reshape(-1,1))\n",
    "X_test_MinExp = sc1.transform(np.array(test_data['Minimum_experience']).reshape(-1,1))\n",
    "X_train_MinExp = sparse.csr_matrix(X_train_MinExp)\n",
    "X_test_MinExp = sparse.csr_matrix(X_test_MinExp)\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "X_train_MaxExp = sc2.fit_transform(np.array(train_data['Maximum_experience']).reshape(-1,1))\n",
    "X_test_MaxExp = sc2.transform(np.array(test_data['Maximum_experience']).reshape(-1,1))\n",
    "X_train_MaxExp = sparse.csr_matrix(X_train_MaxExp)\n",
    "X_test_MaxExp = sparse.csr_matrix(X_test_MaxExp)\n",
    "\n",
    "sc3 = StandardScaler()\n",
    "X_train_comp = sc3.fit_transform(np.array(train_data['company_name_encoded']).reshape(-1,1))\n",
    "X_test_comp = sc3.transform(np.array(test_data['company_name_encoded']).reshape(-1,1))\n",
    "X_train_comp = sparse.csr_matrix(X_train_comp)\n",
    "X_test_comp = sparse.csr_matrix(X_test_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63FdWXqnwhHf"
   },
   "outputs": [],
   "source": [
    "merged_train = hstack((X_train_merged, X_train_location, X_train_MinExp, X_train_MaxExp,X_train_comp))\n",
    "merged_test  = hstack((X_test_merged, X_test_location, X_test_MinExp, X_test_MaxExp,X_test_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gpjvf4-CwhHg",
    "outputId": "b190b1c9-3d0f-49a7-8d9b-c65108c5388b"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(merged_train, label=y_train)\n",
    "\n",
    "param = {'objective': 'multiclass',\n",
    "         'num_iterations': 80,\n",
    "         'learning_rate': 0.03,  \n",
    "         'num_leaves': 15,\n",
    "         'max_depth': 15, \n",
    "         'min_data_in_leaf': 25, \n",
    "         'max_bin': 20, \n",
    "         'min_data_in_bin': 3,   \n",
    "         'num_class': 6,\n",
    "         'metric': 'multi_logloss'\n",
    "         }\n",
    "\n",
    "lgbm = lgb.train(params=param, \n",
    "                 train_set=train_data)\n",
    "\n",
    "predictions = lgbm.predict(merged_test)\n",
    "\n",
    "y_pred_class = []\n",
    "for x in predictions:\n",
    "    y_pred_class.append(np.argmax(x))\n",
    "\n",
    "y_pred_class = le.inverse_transform(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e_E3WfVwhHg"
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(data=y_pred_class, columns=['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW4OCMW2whHh"
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output3.xlsx', engine='xlsxwriter')\n",
    "df_sub.to_excel(writer,sheet_name='Sheet1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8auwAVjywhHh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
