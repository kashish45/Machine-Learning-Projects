{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Hack- Computer Vision Hackathon",
      "provenance": [],
      "authorship_tag": "ABX9TyNABgD68EWtoMm0CFjD+TkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashish45/Machine-Learning-Projects/blob/master/Machine_Hack_Computer_Vision_Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47C7DvWCxBkJ",
        "outputId": "da875a31-395a-4372-b4c0-ef13e5a45836"
      },
      "source": [
        "!wget https://machinehack-be.s3.amazonaws.com/computer_vision_classic_weekend_hackathon_11/Data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-11 06:30:51--  https://machinehack-be.s3.amazonaws.com/computer_vision_classic_weekend_hackathon_11/Data.zip\n",
            "Resolving machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)... 52.219.62.44\n",
            "Connecting to machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)|52.219.62.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 315463646 (301M) [application/octet-stream]\n",
            "Saving to: ‘Data.zip’\n",
            "\n",
            "Data.zip            100%[===================>] 300.85M  12.8MB/s    in 25s     \n",
            "\n",
            "2021-02-11 06:31:18 (12.0 MB/s) - ‘Data.zip’ saved [315463646/315463646]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWvEKN41yOjs"
      },
      "source": [
        "#importing libraries\r\n",
        "import pandas as pd\r\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam,Adagrad\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import os\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "from keras.models import Sequential\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import Model\r\n",
        "from keras import Model\r\n",
        "from os import getcwd\r\n",
        "from keras.layers import Dense, Activation, BatchNormalization\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OxSMFbAy5DF"
      },
      "source": [
        "!unzip -q Data.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRupB_BFy9Uy"
      },
      "source": [
        "TRAIN=\"/content/Data/Train\"\r\n",
        "BATCH_SIZE=16"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93i-djYSzM2-",
        "outputId": "8a8d5303-6ddb-43d7-cb0b-278fa3e1467b"
      },
      "source": [
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1 / 255,\r\n",
        "    rotation_range = 40,\r\n",
        "    width_shift_range=.2,\r\n",
        "    height_shift_range=.2,\r\n",
        "    shear_range=.2,\r\n",
        "    validation_split=0.2,\r\n",
        "    zoom_range=.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode='nearest'\r\n",
        ")\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    TRAIN,\r\n",
        "    subset = 'training',\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    class_mode='categorical',\r\n",
        "    target_size = (224,224)\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "validation_generator = train_datagen.flow_from_directory(\r\n",
        "    TRAIN,\r\n",
        "    subset = 'validation',\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    class_mode='categorical',\r\n",
        "    target_size=(224,224)\r\n",
        ")   "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7578 images belonging to 2 classes.\n",
            "Found 1893 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mojYQ77DzUra"
      },
      "source": [
        "from keras.applications import DenseNet201\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMwZahVQ0LOL"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\r\n",
        "earlyStopping = EarlyStopping(monitor = 'val_accuracy', patience = 15, verbose=0, mode='max')\r\n",
        "mcp_save_xc = ModelCheckpoint(filepath = 'mdl_wts.hdf5', save_best_only = True, monitor = 'val_accuracy', mode = 'max')\r\n",
        "mcp_save_ens = ModelCheckpoint(filepath = 'mdl_wts_en.h5', save_best_only = True, monitor = 'val_accuracy', mode = 'max')\r\n",
        "mcp_save_ens1 = ModelCheckpoint(filepath =' mdl_wts_en1.h5', save_best_only = True, monitor = 'val_loss', mode = 'min')\r\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor = 'val_loss', patience=2, verbose=1, min_delta = 1e-4, mode = 'min')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xeea1TU0M9i"
      },
      "source": [
        "pre_model = DenseNet201( input_shape = (224,224,3), include_top = False , weights = \"imagenet\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXTZZFjH0OGD"
      },
      "source": [
        "for layer in pre_model.layers:\r\n",
        "  layer.trainable = True"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsJyi3sk0RFU",
        "outputId": "aa9792f6-f952-41d2-829d-0ab53e26142a"
      },
      "source": [
        "last_layer = pre_model.get_layer('relu')\r\n",
        "print('last layer output shape:', last_layer.output_shape)\r\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 1920)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ1f-YIa0TNp"
      },
      "source": [
        "#for xception\r\n",
        "x = layers.Flatten()(last_output)\r\n",
        "\r\n",
        "x = layers.Dropout(0.4)(x)\r\n",
        "\r\n",
        "x = layers.Dense(1024, activation = \"relu\")(x)\r\n",
        "\r\n",
        "x = layers.Dropout(0.4)(x)\r\n",
        "\r\n",
        "x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "x = layers.Dense(2, activation = \"softmax\")(x)\r\n",
        "\r\n",
        "model_xception = Model(pre_model.input,x)\r\n",
        "\r\n",
        "model_xception.compile(optimizer = Adagrad(lr=0.001), \r\n",
        "              loss = 'categorical_crossentropy', \r\n",
        "              metrics = ['accuracy']\r\n",
        "             )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoPqXy4E0VnC",
        "outputId": "246ecb98-8908-4b0b-ae02-c29b16cb6198"
      },
      "source": [
        "history_xc = model_xception.fit(\r\n",
        "      train_generator,  \r\n",
        "      callbacks=[ mcp_save_xc, reduce_lr_loss,earlyStopping],\r\n",
        "      validation_data = validation_generator,\r\n",
        "      epochs = 20,\r\n",
        "      verbose = 1,\r\n",
        " )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "474/474 [==============================] - 247s 485ms/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.0442 - val_accuracy: 0.9826\n",
            "Epoch 2/20\n",
            "474/474 [==============================] - 222s 469ms/step - loss: 0.0711 - accuracy: 0.9732 - val_loss: 0.0337 - val_accuracy: 0.9857\n",
            "Epoch 3/20\n",
            "474/474 [==============================] - 222s 468ms/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.0339 - val_accuracy: 0.9878\n",
            "Epoch 4/20\n",
            "474/474 [==============================] - 223s 470ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.0276 - val_accuracy: 0.9878\n",
            "Epoch 5/20\n",
            "474/474 [==============================] - 223s 470ms/step - loss: 0.0571 - accuracy: 0.9821 - val_loss: 0.0326 - val_accuracy: 0.9868\n",
            "Epoch 6/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0438 - accuracy: 0.9851 - val_loss: 0.0291 - val_accuracy: 0.9884\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 7/20\n",
            "474/474 [==============================] - 223s 470ms/step - loss: 0.0318 - accuracy: 0.9888 - val_loss: 0.0252 - val_accuracy: 0.9900\n",
            "Epoch 8/20\n",
            "474/474 [==============================] - 224s 472ms/step - loss: 0.0393 - accuracy: 0.9857 - val_loss: 0.0239 - val_accuracy: 0.9921\n",
            "Epoch 9/20\n",
            "474/474 [==============================] - 223s 470ms/step - loss: 0.0276 - accuracy: 0.9898 - val_loss: 0.0204 - val_accuracy: 0.9931\n",
            "Epoch 10/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0273 - accuracy: 0.9895 - val_loss: 0.0215 - val_accuracy: 0.9905\n",
            "Epoch 11/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0409 - accuracy: 0.9864 - val_loss: 0.0204 - val_accuracy: 0.9921\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 12/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0299 - accuracy: 0.9888 - val_loss: 0.0226 - val_accuracy: 0.9905\n",
            "Epoch 13/20\n",
            "474/474 [==============================] - 224s 472ms/step - loss: 0.0329 - accuracy: 0.9883 - val_loss: 0.0216 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 14/20\n",
            "474/474 [==============================] - 224s 472ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.0157 - val_accuracy: 0.9926\n",
            "Epoch 15/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 0.0223 - val_accuracy: 0.9926\n",
            "Epoch 16/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0318 - accuracy: 0.9887 - val_loss: 0.0222 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 17/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.0166 - val_accuracy: 0.9931\n",
            "Epoch 18/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 0.0185 - val_accuracy: 0.9926\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 19/20\n",
            "474/474 [==============================] - 223s 470ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.0190 - val_accuracy: 0.9910\n",
            "Epoch 20/20\n",
            "474/474 [==============================] - 223s 471ms/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 0.0220 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3SQ4JiO0YOK"
      },
      "source": [
        "test_dir ='/content/Data/testing/'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHyKLKWtGjme",
        "outputId": "7c341875-ee63-4543-c94c-80f79130a338"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255) \r\n",
        "test_generator = test_datagen.flow_from_directory(\r\n",
        "        test_dir,\r\n",
        "        target_size=(224,224),\r\n",
        "        #classes=['test'],\r\n",
        "        shuffle=False,\r\n",
        "        class_mode = 'categorical')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4059 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y17xM29OIK4e"
      },
      "source": [
        "predict = model_xception.predict(test_generator , steps=None )"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-jBt3RHIRU0",
        "outputId": "d43d5879-f84b-41d3-a116-a21f02a8357e"
      },
      "source": [
        "prediction_cls_idx = predict.argmax(axis=-1)\r\n",
        "prediction_cls_idx"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3iGttoiIgr4"
      },
      "source": [
        "from zipfile import ZipFile as zip\r\n",
        "import numpy as np\r\n",
        "idx_to_cls = {v: k for k, v in train_generator.class_indices.items()}\r\n",
        "prediction_cls= np.vectorize(idx_to_cls.get)(prediction_cls_idx)\r\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN9mp_BvIj0j"
      },
      "source": [
        "filenames_to_cls = list((test_generator.filenames, prediction_cls))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFPuopfeI0W3"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = pd.DataFrame(filenames_to_cls)\r\n",
        "data = data.T\r\n",
        "data.columns = ['File_Name', 'Category'] "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiGDuJlCJeNE"
      },
      "source": [
        "data['File_Name'] = data['File_Name'].str.replace('Test/','')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FABZ2hBJiq6"
      },
      "source": [
        "data.to_csv('output.csv', index = False)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wyp_8BrKFbC"
      },
      "source": [
        "data['Category']=data['Category'].replace('Dogs',1)\r\n",
        "data['Category']=data['Category'].replace('Cats',0)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "MdtZjjrTJk_D",
        "outputId": "bb8e6fe2-8db1-4c54-dc70-1da2e2284f0c"
      },
      "source": [
        "data.head(20)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File_Name</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10005.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10007.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10008.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10009.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10011.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10012.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10013.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10014.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10018.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10020.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10021.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10023.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10024.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>10038.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1004.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10042.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>10051.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10056.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>10059.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10060.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    File_Name  Category\n",
              "0   10005.jpg         1\n",
              "1   10007.jpg         1\n",
              "2   10008.jpg         0\n",
              "3   10009.jpg         0\n",
              "4   10011.jpg         0\n",
              "5   10012.jpg         0\n",
              "6   10013.jpg         0\n",
              "7   10014.jpg         1\n",
              "8   10018.jpg         0\n",
              "9   10020.jpg         0\n",
              "10  10021.jpg         0\n",
              "11  10023.jpg         1\n",
              "12  10024.jpg         0\n",
              "13  10038.jpg         0\n",
              "14   1004.jpg         0\n",
              "15  10042.jpg         1\n",
              "16  10051.jpg         0\n",
              "17  10056.jpg         1\n",
              "18  10059.jpg         1\n",
              "19  10060.jpg         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAo2BU7CJmNF"
      },
      "source": [
        "data.to_csv('o.csv', index = False)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liKa-CjlKZuT",
        "outputId": "4f3553fc-1424-4fae-93e4-3b37d7b2ac85"
      },
      "source": [
        "data['Category'].value_counts()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2045\n",
              "0    2014\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4a9dE1gLgjp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}